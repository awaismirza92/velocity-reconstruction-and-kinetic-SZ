{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import multiprocessing as multi\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capturing name of the PC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture PC_name \n",
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting notebook parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "science12\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "#setting dots per inch for images\n",
    "dpi = 90\n",
    "\n",
    "#setting number of processors for multiprocessing\n",
    "PC_name_str = PC_name.stdout[0:-2]\n",
    "\n",
    "if PC_name_str == 'science12':\n",
    "    cores = 42        \n",
    "else:\n",
    "    cores = multi.cpu_count()\n",
    "\n",
    "print(PC_name_str)\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "omega_m = 0.272            #matter density paratmeter from Komatsu et al. (2011) \n",
    "omega_l = 1 - omega_m      #vacuum density paratmeter assuming flat universe\n",
    "H_o = 70.4                 #Hubble constant in km s^−1 Mpc^−1 from Komatsu et al. (2011) \n",
    "h = 0.704\n",
    "f = omega_m**0.545         #linear velocity growth rate from Tanimura et al. (2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(z):                           #hubble parameter (in km s^-1 Mpc^-1) using Eq. 4.33 in Peter's book\n",
    "    return np.sqrt( H_o**2 * ( (1+z)**3 * omega_m + omega_l ) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading galaxies dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x[kpc/h]</th>\n",
       "      <th>y[kpc/h]</th>\n",
       "      <th>z[kpc/h]</th>\n",
       "      <th>m[Msol/h]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93097.000000</td>\n",
       "      <td>93097.000000</td>\n",
       "      <td>93097.000000</td>\n",
       "      <td>9.309700e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325576.133087</td>\n",
       "      <td>322500.028738</td>\n",
       "      <td>320613.762863</td>\n",
       "      <td>3.993206e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>184863.273960</td>\n",
       "      <td>182799.587421</td>\n",
       "      <td>183249.915097</td>\n",
       "      <td>3.995129e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.864417</td>\n",
       "      <td>10.164207</td>\n",
       "      <td>0.260974</td>\n",
       "      <td>1.800010e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>163866.950000</td>\n",
       "      <td>166201.380000</td>\n",
       "      <td>162514.560000</td>\n",
       "      <td>2.161480e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>332449.620000</td>\n",
       "      <td>329260.160000</td>\n",
       "      <td>319925.780000</td>\n",
       "      <td>2.784900e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>483949.000000</td>\n",
       "      <td>475466.120000</td>\n",
       "      <td>478698.410000</td>\n",
       "      <td>4.192930e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>639996.190000</td>\n",
       "      <td>639980.940000</td>\n",
       "      <td>639993.120000</td>\n",
       "      <td>1.077460e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x[kpc/h]       y[kpc/h]       z[kpc/h]     m[Msol/h]\n",
       "count   93097.000000   93097.000000   93097.000000  9.309700e+04\n",
       "mean   325576.133087  322500.028738  320613.762863  3.993206e+11\n",
       "std    184863.273960  182799.587421  183249.915097  3.995129e+11\n",
       "min         1.864417      10.164207       0.260974  1.800010e+11\n",
       "25%    163866.950000  166201.380000  162514.560000  2.161480e+11\n",
       "50%    332449.620000  329260.160000  319925.780000  2.784900e+11\n",
       "75%    483949.000000  475466.120000  478698.410000  4.192930e+11\n",
       "max    639996.190000  639980.940000  639993.120000  1.077460e+13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "z = 0.42372720\n",
    "# data_address = '../input/magneticumsnap027z042-massfiltered/'\n",
    "data_address = 'Data/'\n",
    "df_gal = pd.read_csv(data_address + 'massive_galaxies.csv')      #massive_galaxies.csv contains galaxies with mass greater than 1.8 ×10^{11} h^{−1} M_sun as done by Tanimura et al. (2020)\n",
    "df_gal.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x[kpc/h]</th>\n",
       "      <th>y[kpc/h]</th>\n",
       "      <th>z[kpc/h]</th>\n",
       "      <th>m[Msol/h]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.513619e+06</td>\n",
       "      <td>2.513619e+06</td>\n",
       "      <td>2.513619e+06</td>\n",
       "      <td>2.513619e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.655761e+05</td>\n",
       "      <td>9.625000e+05</td>\n",
       "      <td>9.606138e+05</td>\n",
       "      <td>3.993206e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.542931e+05</td>\n",
       "      <td>5.536083e+05</td>\n",
       "      <td>5.537571e+05</td>\n",
       "      <td>3.995109e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.864417e+00</td>\n",
       "      <td>1.016421e+01</td>\n",
       "      <td>2.609741e-01</td>\n",
       "      <td>1.800010e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.839490e+05</td>\n",
       "      <td>4.754661e+05</td>\n",
       "      <td>4.786984e+05</td>\n",
       "      <td>2.161480e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.724496e+05</td>\n",
       "      <td>9.692602e+05</td>\n",
       "      <td>9.599258e+05</td>\n",
       "      <td>2.784900e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.443867e+06</td>\n",
       "      <td>1.446201e+06</td>\n",
       "      <td>1.442515e+06</td>\n",
       "      <td>4.192930e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.919996e+06</td>\n",
       "      <td>1.919981e+06</td>\n",
       "      <td>1.919993e+06</td>\n",
       "      <td>1.077460e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x[kpc/h]      y[kpc/h]      z[kpc/h]     m[Msol/h]\n",
       "count  2.513619e+06  2.513619e+06  2.513619e+06  2.513619e+06\n",
       "mean   9.655761e+05  9.625000e+05  9.606138e+05  3.993206e+11\n",
       "std    5.542931e+05  5.536083e+05  5.537571e+05  3.995109e+11\n",
       "min    1.864417e+00  1.016421e+01  2.609741e-01  1.800010e+11\n",
       "25%    4.839490e+05  4.754661e+05  4.786984e+05  2.161480e+11\n",
       "50%    9.724496e+05  9.692602e+05  9.599258e+05  2.784900e+11\n",
       "75%    1.443867e+06  1.446201e+06  1.442515e+06  4.192930e+11\n",
       "max    1.919996e+06  1.919981e+06  1.919993e+06  1.077460e+13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gal_temp = df_gal.copy()\n",
    "\n",
    "df_gal_big = pd.DataFrame()\n",
    "\n",
    "for k in range(3):\n",
    "    for i in range(3):\n",
    "        for j in range(0,3):\n",
    "\n",
    "            df_gal_temp['x[kpc/h]'] = df_gal['x[kpc/h]'] + (640000 * i)\n",
    "            df_gal_temp['y[kpc/h]'] = df_gal['y[kpc/h]'] + (640000 * j)\n",
    "            df_gal_temp['z[kpc/h]'] = df_gal['z[kpc/h]'] + (640000 * k)\n",
    "\n",
    "            df_gal_big = df_gal_big.append(df_gal_temp)\n",
    "\n",
    "df_gal_big.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading clusters dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x[kpc/h]</th>\n",
       "      <th>y[kpc/h]</th>\n",
       "      <th>z[kpc/h]</th>\n",
       "      <th>m500c[Msol/h]</th>\n",
       "      <th>vx[km/s]</th>\n",
       "      <th>vy[km/s]</th>\n",
       "      <th>vz[km/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6080.000000</td>\n",
       "      <td>6080.000000</td>\n",
       "      <td>6080.000000</td>\n",
       "      <td>6.080000e+03</td>\n",
       "      <td>6080.000000</td>\n",
       "      <td>6080.000000</td>\n",
       "      <td>6080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326416.401838</td>\n",
       "      <td>322055.402286</td>\n",
       "      <td>321308.240244</td>\n",
       "      <td>6.356245e+13</td>\n",
       "      <td>2.109102</td>\n",
       "      <td>-1.647297</td>\n",
       "      <td>-4.296055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>186021.550694</td>\n",
       "      <td>182650.899538</td>\n",
       "      <td>183665.854310</td>\n",
       "      <td>4.851698e+13</td>\n",
       "      <td>316.064539</td>\n",
       "      <td>306.226537</td>\n",
       "      <td>286.454388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.163288</td>\n",
       "      <td>152.653880</td>\n",
       "      <td>87.370949</td>\n",
       "      <td>3.162340e+13</td>\n",
       "      <td>-1179.530000</td>\n",
       "      <td>-1163.520000</td>\n",
       "      <td>-1104.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>160978.575000</td>\n",
       "      <td>164793.430000</td>\n",
       "      <td>161863.925000</td>\n",
       "      <td>3.795035e+13</td>\n",
       "      <td>-200.229000</td>\n",
       "      <td>-205.139250</td>\n",
       "      <td>-190.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>338884.565000</td>\n",
       "      <td>333274.345000</td>\n",
       "      <td>322110.075000</td>\n",
       "      <td>4.801630e+13</td>\n",
       "      <td>-3.619450</td>\n",
       "      <td>1.969450</td>\n",
       "      <td>-8.055475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>486227.747500</td>\n",
       "      <td>473556.765000</td>\n",
       "      <td>478893.610000</td>\n",
       "      <td>6.945502e+13</td>\n",
       "      <td>206.816750</td>\n",
       "      <td>207.755750</td>\n",
       "      <td>181.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>639887.560000</td>\n",
       "      <td>639933.380000</td>\n",
       "      <td>639848.380000</td>\n",
       "      <td>7.438200e+14</td>\n",
       "      <td>1197.640000</td>\n",
       "      <td>1164.960000</td>\n",
       "      <td>1201.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            x[kpc/h]       y[kpc/h]       z[kpc/h]  m500c[Msol/h]  \\\n",
       "count    6080.000000    6080.000000    6080.000000   6.080000e+03   \n",
       "mean   326416.401838  322055.402286  321308.240244   6.356245e+13   \n",
       "std    186021.550694  182650.899538  183665.854310   4.851698e+13   \n",
       "min        19.163288     152.653880      87.370949   3.162340e+13   \n",
       "25%    160978.575000  164793.430000  161863.925000   3.795035e+13   \n",
       "50%    338884.565000  333274.345000  322110.075000   4.801630e+13   \n",
       "75%    486227.747500  473556.765000  478893.610000   6.945502e+13   \n",
       "max    639887.560000  639933.380000  639848.380000   7.438200e+14   \n",
       "\n",
       "          vx[km/s]     vy[km/s]     vz[km/s]  \n",
       "count  6080.000000  6080.000000  6080.000000  \n",
       "mean      2.109102    -1.647297    -4.296055  \n",
       "std     316.064539   306.226537   286.454388  \n",
       "min   -1179.530000 -1163.520000 -1104.790000  \n",
       "25%    -200.229000  -205.139250  -190.806000  \n",
       "50%      -3.619450     1.969450    -8.055475  \n",
       "75%     206.816750   207.755750   181.532000  \n",
       "max    1197.640000  1164.960000  1201.260000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters_orig = pd.read_csv(data_address + 'massive_clusters.csv', \n",
    "                          usecols = ['x[kpc/h]', 'y[kpc/h]', 'z[kpc/h]', 'm500c[Msol/h]', 'vx[km/s]', 'vy[km/s]', 'vz[km/s]'    ])  #massive_clusters.csv contains clusters with M_500c greater than 10^13.5 h^{-1} M_sun as done by Tanimura et al. (2020)\n",
    "\n",
    "df_clusters_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x[kpc/h]</th>\n",
       "      <th>y[kpc/h]</th>\n",
       "      <th>z[kpc/h]</th>\n",
       "      <th>m500c[Msol/h]</th>\n",
       "      <th>vx[km/s]</th>\n",
       "      <th>vy[km/s]</th>\n",
       "      <th>vz[km/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.641600e+05</td>\n",
       "      <td>1.641600e+05</td>\n",
       "      <td>1.641600e+05</td>\n",
       "      <td>1.641600e+05</td>\n",
       "      <td>164160.000000</td>\n",
       "      <td>164160.000000</td>\n",
       "      <td>164160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.664164e+05</td>\n",
       "      <td>9.620554e+05</td>\n",
       "      <td>9.613082e+05</td>\n",
       "      <td>6.356245e+13</td>\n",
       "      <td>2.109102</td>\n",
       "      <td>-1.647297</td>\n",
       "      <td>-4.296055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.546773e+05</td>\n",
       "      <td>5.535561e+05</td>\n",
       "      <td>5.538918e+05</td>\n",
       "      <td>4.851314e+13</td>\n",
       "      <td>316.039508</td>\n",
       "      <td>306.202286</td>\n",
       "      <td>286.431703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.916329e+01</td>\n",
       "      <td>1.526539e+02</td>\n",
       "      <td>8.737095e+01</td>\n",
       "      <td>3.162340e+13</td>\n",
       "      <td>-1179.530000</td>\n",
       "      <td>-1163.520000</td>\n",
       "      <td>-1104.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.863366e+05</td>\n",
       "      <td>4.736062e+05</td>\n",
       "      <td>4.789278e+05</td>\n",
       "      <td>3.795035e+13</td>\n",
       "      <td>-200.229000</td>\n",
       "      <td>-205.139250</td>\n",
       "      <td>-190.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.788846e+05</td>\n",
       "      <td>9.732743e+05</td>\n",
       "      <td>9.621101e+05</td>\n",
       "      <td>4.801630e+13</td>\n",
       "      <td>-3.619450</td>\n",
       "      <td>1.969450</td>\n",
       "      <td>-8.055475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.440918e+06</td>\n",
       "      <td>1.444771e+06</td>\n",
       "      <td>1.441655e+06</td>\n",
       "      <td>6.945502e+13</td>\n",
       "      <td>206.816750</td>\n",
       "      <td>207.755750</td>\n",
       "      <td>181.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.919888e+06</td>\n",
       "      <td>1.919933e+06</td>\n",
       "      <td>1.919848e+06</td>\n",
       "      <td>7.438200e+14</td>\n",
       "      <td>1197.640000</td>\n",
       "      <td>1164.960000</td>\n",
       "      <td>1201.260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x[kpc/h]      y[kpc/h]      z[kpc/h]  m500c[Msol/h]       vx[km/s]  \\\n",
       "count  1.641600e+05  1.641600e+05  1.641600e+05   1.641600e+05  164160.000000   \n",
       "mean   9.664164e+05  9.620554e+05  9.613082e+05   6.356245e+13       2.109102   \n",
       "std    5.546773e+05  5.535561e+05  5.538918e+05   4.851314e+13     316.039508   \n",
       "min    1.916329e+01  1.526539e+02  8.737095e+01   3.162340e+13   -1179.530000   \n",
       "25%    4.863366e+05  4.736062e+05  4.789278e+05   3.795035e+13    -200.229000   \n",
       "50%    9.788846e+05  9.732743e+05  9.621101e+05   4.801630e+13      -3.619450   \n",
       "75%    1.440918e+06  1.444771e+06  1.441655e+06   6.945502e+13     206.816750   \n",
       "max    1.919888e+06  1.919933e+06  1.919848e+06   7.438200e+14    1197.640000   \n",
       "\n",
       "            vy[km/s]       vz[km/s]  \n",
       "count  164160.000000  164160.000000  \n",
       "mean       -1.647297      -4.296055  \n",
       "std       306.202286     286.431703  \n",
       "min     -1163.520000   -1104.790000  \n",
       "25%      -205.139250    -190.806000  \n",
       "50%         1.969450      -8.055475  \n",
       "75%       207.755750     181.532000  \n",
       "max      1164.960000    1201.260000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters_temp = df_clusters_orig.copy()\n",
    "\n",
    "df_clusters_big = pd.DataFrame()\n",
    "\n",
    "for k in range(3):\n",
    "    for i in range(3):\n",
    "        for j in range(0,3):\n",
    "\n",
    "            df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * i)\n",
    "            df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * j)\n",
    "            df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * k)\n",
    "\n",
    "            df_clusters_big = df_clusters_big.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_big.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 0)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 1)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)\n",
    "\n",
    "df_clusters_temp['x[kpc/h]'] = df_clusters_orig['x[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['y[kpc/h]'] = df_clusters_orig['y[kpc/h]'] + (640000 * 2)\n",
    "df_clusters_temp['z[kpc/h]'] = df_clusters_orig['z[kpc/h]'] + (640000 * 0)\n",
    "\n",
    "df_clusters_big = df_clusters_orig.append(df_clusters_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing clusters at edges of the simulation box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_clus_remover(clus_cube_size):\n",
    "    \n",
    "    low_bound = clus_cube_size//2\n",
    "    upp_bound = 640000 - (clus_cube_size//2)\n",
    "    \n",
    "    df_clusters = df_clusters_orig[(df_clusters_orig['x[kpc/h]'] > low_bound) & \n",
    "                                   (df_clusters_orig['x[kpc/h]'] < upp_bound) & \n",
    "                                   (df_clusters_orig['y[kpc/h]'] > low_bound) & \n",
    "                                   (df_clusters_orig['y[kpc/h]'] < upp_bound) & \n",
    "                                   (df_clusters_orig['z[kpc/h]'] > low_bound) & \n",
    "                                   (df_clusters_orig['z[kpc/h]'] < upp_bound)]\n",
    "    \n",
    "    return df_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying prefactors for Eq. 1 of Tanimura et al. (2020)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1/(1+z)\n",
    "H(z)\n",
    "print(H(z))\n",
    "\n",
    "pre_fac = (f * a * H(z) / (4 * np.pi))           #in km s^−1 Mpc^−1 \n",
    "pre_fac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating mean density of the simulation box for Eq. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_gal_mean_func(cell_size):\n",
    "    \n",
    "    df_gal_mean = df_gal.copy()\n",
    "\n",
    "    df_gal_mean['x[kpc/h]'] = df_gal_mean['x[kpc/h]'] / cell_size\n",
    "    df_gal_mean['y[kpc/h]'] = df_gal_mean['y[kpc/h]'] / cell_size\n",
    "    df_gal_mean['z[kpc/h]'] = df_gal_mean['z[kpc/h]'] / cell_size\n",
    "\n",
    "    #making tuples, converting tuples to cell coordinates\n",
    "    df_gal_mean[\"cell\"] = list(zip(df_gal_mean['x[kpc/h]'].astype(int), df_gal_mean['y[kpc/h]'].astype(int), df_gal_mean['z[kpc/h]'].astype(int)))\n",
    "\n",
    "    #array to store number of galaxies in the cells\n",
    "    gals_in_cell = np.zeros((640000//cell_size, 640000//cell_size, 640000//cell_size))\n",
    "    \n",
    "    #counting number of galaxies in the cells\n",
    "    for cell in df_gal_mean[\"cell\"]:\n",
    "        x, y, z = cell\n",
    "        gals_in_cell[x, y, z] += 1\n",
    "\n",
    "    delta_gal_mean = np.mean(gals_in_cell)\n",
    "    \n",
    "    return delta_gal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating Overdensity field for Eq. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2                                #bias for LOWZ & CMASS galaxies as taken by Tanimura et al. 2020\n",
    "\n",
    "def overdensity_field_calc(clus_x, clus_y, clus_z, delta_gal_mean, cell_size, sigma_in_pix, clus_cube_size):\n",
    "\n",
    "    #converting strings into floats\n",
    "    clus_x = float(clus_x); clus_y = float(clus_y); clus_z = float(clus_z)\n",
    "    \n",
    "    #filtering galaxies in a cube of 240,000 h^-1 kpc around the given cluster\n",
    "    df_gal_select = df_gal[(df_gal['x[kpc/h]'] > (clus_x - clus_cube_size//2)) & \n",
    "                           (df_gal['x[kpc/h]'] < (clus_x + clus_cube_size//2)) & \n",
    "                           (df_gal['y[kpc/h]'] > (clus_y - clus_cube_size//2)) & \n",
    "                           (df_gal['y[kpc/h]'] < (clus_y + clus_cube_size//2)) & \n",
    "                           (df_gal['z[kpc/h]'] > (clus_z - clus_cube_size//2)) & \n",
    "                           (df_gal['z[kpc/h]'] < (clus_z + clus_cube_size//2))]\n",
    "    \n",
    "    #making copy to extract coordinates of cells containing the galaxies\n",
    "    df_gal_cube = df_gal_select.copy()\n",
    "    \n",
    "    #moving the galxies cube to lie within 0 to 240,000 h^-1 kpc \n",
    "    df_gal_cube['x[kpc/h]'] -= (clus_x - clus_cube_size//2)\n",
    "    df_gal_cube['y[kpc/h]'] -= (clus_y - clus_cube_size//2)\n",
    "    df_gal_cube['z[kpc/h]'] -= (clus_z - clus_cube_size//2)\n",
    "\n",
    "    #dividing by 5000 (integer-div) so we get cell coordinates\n",
    "    df_gal_cube['x[kpc/h]'] = df_gal_cube['x[kpc/h]'] / cell_size\n",
    "    df_gal_cube['y[kpc/h]'] = df_gal_cube['y[kpc/h]'] / cell_size\n",
    "    df_gal_cube['z[kpc/h]'] = df_gal_cube['z[kpc/h]'] / cell_size\n",
    "    \n",
    "    #making tuples, converting tuples to cell coordinates\n",
    "    df_gal_cube[\"cell\"] = list(zip(df_gal_cube['x[kpc/h]'].astype(int), df_gal_cube['y[kpc/h]'].astype(int), df_gal_cube['z[kpc/h]'].astype(int)))\n",
    "    \n",
    "    #array to store number of galaxies in the cells\n",
    "    gals_in_cell = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    \n",
    "    #counting number of galaxies in the cells\n",
    "    for cell in df_gal_cube[\"cell\"]:\n",
    "        x, y, z = cell\n",
    "        gals_in_cell[x, y, z] += 1\n",
    "        \n",
    "    #determining the overdensity of galaxies    \n",
    "    delta_gal = (gals_in_cell/delta_gal_mean) - 1\n",
    "    \n",
    "    #smoothing the overdensity of galaxies\n",
    "    delta_gal_smooth = gaussian_filter(delta_gal, sigma = sigma_in_pix)\n",
    "        \n",
    "    #obtaining matter overdensity from galaxies overdensity\n",
    "    delta_matter = delta_gal_smooth / b\n",
    "    \n",
    "    return delta_matter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating differential, numerator & denominator for Eq. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vel_terms_calc(cell_size, clus_cube_size):\n",
    "    \n",
    "    #calculating the differential in the Eq. 1\n",
    "    dy_cubed = cell_size**3\n",
    "    \n",
    "    #specifing position of the clusters\n",
    "    Rclus_x = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    Rclus_x[:] = clus_cube_size//2\n",
    "    Rclus_y = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    Rclus_y[:] = clus_cube_size//2\n",
    "    Rclus_z = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    Rclus_z[:] = clus_cube_size//2\n",
    "\n",
    "    #generating meshgrid containing coordinates of the centers of cells\n",
    "    Rcell_x = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    Rcell_y = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "    Rcell_z = np.zeros((clus_cube_size//cell_size, clus_cube_size//cell_size, clus_cube_size//cell_size))\n",
    "\n",
    "    for i, val in enumerate(range(cell_size//2, clus_cube_size, cell_size)):\n",
    "        Rcell_x[i,:,:] = val\n",
    "        Rcell_y[:,i,:] = val\n",
    "        Rcell_z[:,:,i] = val\n",
    "\n",
    "    #evaluating the term in the denominator of Eq. 1 of Tanimura et al. 2020\n",
    "    denom = np.sqrt((Rcell_x - Rclus_x)**2 + (Rcell_y - Rclus_y)**2 + (Rcell_z - Rclus_z)**2)**(3)\n",
    "\n",
    "    #evaluating the direction term in the numerator of Eq. 1\n",
    "    numer_x = Rcell_x - Rclus_x\n",
    "    numer_y = Rcell_y - Rclus_y\n",
    "    numer_z = Rcell_z - Rclus_z\n",
    "    \n",
    "    return (dy_cubed, numer_x, numer_y, numer_z, denom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating velocity of clusters according to Eq. 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clus_velocity_calc(clus_x, clus_y, clus_z, delta_gal_mean, cell_size, vel_terms, sigma_in_pix, \n",
    "                       clus_cube_size):\n",
    "    \n",
    "    delta_matter = overdensity_field_calc(clus_x, clus_y, clus_z, delta_gal_mean, cell_size, sigma_in_pix, \n",
    "                                          clus_cube_size)\n",
    "    \n",
    "    \n",
    "    dy_cubed, numer_x, numer_y, numer_z, denom = vel_terms\n",
    "       \n",
    "    #estimating velocity in x direction\n",
    "    integrand_x = dy_cubed * delta_matter * (numer_x/(h*1e3)) / denom #in units of Mpc    \n",
    "    vx_est = pre_fac * np.sum(integrand_x)\n",
    "        \n",
    "    #estimating velocity in y direction\n",
    "    integrand_y = dy_cubed * delta_matter * (numer_y/(h*1e3)) / denom #in units of Mpc    \n",
    "    vy_est = pre_fac * np.sum(integrand_y)\n",
    "    \n",
    "    #estimating velocity in z direction\n",
    "    integrand_z = dy_cubed * delta_matter * (numer_z/(h*1e3)) / denom #in units of Mpc    \n",
    "    vz_est = pre_fac * np.sum(integrand_z)\n",
    "    \n",
    "    return(vx_est, vy_est, vz_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating sigma for smoothing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_calc(cell_size):\n",
    "    \n",
    "    FWHM = 2000                           #h^-1 kpc, of Gaussian kernel, taken by Tanimura et al. 2020\n",
    "    FWHM_in_pix = FWHM/cell_size          #in pixel units\n",
    "    sigma_in_pix = FWHM_in_pix/(2.35482)  #in pixel units\n",
    "    \n",
    "    return sigma_in_pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the scatter plots & histograms for assesment of velocity estimates **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotting_func(df_clusters_est_err, cell_size, clus_cube_size_actual):\n",
    "    \n",
    "    fig = plt.figure(dpi = dpi, figsize = (10,12))\n",
    "\n",
    "    plt.subplot(3,2,1)\n",
    "    plt.scatter(df_clusters_est_err['vx[km/s]'], df_clusters_est_err['vx_est[km/s]'], s = 8)\n",
    "    plt.xlabel('V$_\\mathrm{x, true}$ (km/s)')\n",
    "    plt.ylabel('V$_\\mathrm{x, estimated}$ (km/s)')\n",
    "    plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "    plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "    plt.ylim(-2000,2000)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title('Vx - scatter plot')\n",
    "\n",
    "    plt.subplot(3,2,2)\n",
    "    error_x = df_clusters_est_err['vx[km/s]'] - df_clusters_est_err['vx_est[km/s]']\n",
    "    plt.hist(error_x, bins = 100)\n",
    "    plt.xlabel('Error in V$_{\\mathrm{x}}$ (km/s)')\n",
    "    plt.ylabel('Number of clusters')\n",
    "    x_low, x_high = plt.xlim()\n",
    "    plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "    minus_one = {-1}\n",
    "    plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.76, f'Mean: {round(np.mean(error_x), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.69, f'SD: {round(np.std(error_x), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    r_vx = np.corrcoef(df_clusters_est_err['vx[km/s]'], df_clusters_est_err['vx_est[km/s]'])[1,0]\n",
    "    plt.text(0.6, 0.62, f'Pearson\\'s r: {round(r_vx, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.title('Vx error - histogram')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(3,2,3)\n",
    "    plt.scatter(df_clusters_est_err['vy[km/s]'], df_clusters_est_err['vy_est[km/s]'], s = 8)\n",
    "    plt.xlabel('V$_\\mathrm{y, true}$ (km/s)')\n",
    "    plt.ylabel('V$_\\mathrm{y, estimated}$ (km/s)')\n",
    "    plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "    plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "    plt.ylim(-2000,2000)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title('Vy - scatter plot')\n",
    "\n",
    "    plt.subplot(3,2,4)\n",
    "    error_y = df_clusters_est_err['vy[km/s]'] - df_clusters_est_err['vy_est[km/s]']\n",
    "    plt.hist(error_y, bins = 100)\n",
    "    plt.xlabel('Error in V$_{\\mathrm{y}}$ (km/s)')\n",
    "    plt.ylabel('Number of clusters')\n",
    "    x_low, x_high = plt.xlim()\n",
    "    plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "    plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.76, f'Mean: {round(np.mean(error_y), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.69, f'SD: {round(np.std(error_y), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    r_vy = np.corrcoef(df_clusters_est_err['vy[km/s]'], df_clusters_est_err['vy_est[km/s]'])[1,0]\n",
    "    plt.text(0.6, 0.62, f'Pearson\\'s r: {round(r_vy, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.title('Vy error - histogram')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.subplot(3,2,5)\n",
    "    plt.scatter(df_clusters_est_err['vz[km/s]'], df_clusters_est_err['vz_est[km/s]'], s = 8)\n",
    "    plt.xlabel('V$_\\mathrm{z, true}$ (km/s)')\n",
    "    plt.ylabel('V$_\\mathrm{z, estimated}$ (km/s)');\n",
    "    plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "    plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "    plt.ylim(-2000,2000)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.title('Vz - scatter plot')\n",
    "\n",
    "    plt.subplot(3,2,6)\n",
    "    error_z = df_clusters_est_err['vz[km/s]'] - df_clusters_est_err['vz_est[km/s]']\n",
    "    plt.hist(error_z, bins = 100)\n",
    "    plt.xlabel('Error in V$_{\\mathrm{z}}$ (km/s)')\n",
    "    plt.ylabel('Number of clusters')\n",
    "    x_low, x_high = plt.xlim()\n",
    "    plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "    plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.76, f'Mean: {round(np.mean(error_z), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    plt.text(0.6, 0.69, f'SD: {round(np.std(error_z), 1)} km/s', transform=plt.gca().transAxes)\n",
    "    r_vz = np.corrcoef(df_clusters_est_err['vz[km/s]'], df_clusters_est_err['vz_est[km/s]'])[1,0]\n",
    "    plt.text(0.6, 0.62, f'Pearson\\'s r: {round(r_vz, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.title('Vz error - histogram')\n",
    "\n",
    "    os.system(f'mkdir Plots/v_scatter_hist/{clus_cube_size_actual}')\n",
    "    plt.subplots_adjust(top = 0.9, hspace = 0.4, wspace = 0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Plots/v_scatter_hist/{clus_cube_size_actual}/v_scatter_hist_{cell_size}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examining the effects of cluster cube & cell sizes variation on velocity estimates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cell_size = 10000                      #h^-1 kpc, size of pixel or cell\n",
    "\n",
    "cube_cell_size_assess = pd.DataFrame(columns=['Cell Size', 'Act Cube Size', 'Cube Size Set', 'Clusters', 'Mean - Vx', 'Mean - Vy', \n",
    "                                              'Mean - Vz', 'SD - Vx', 'SD - Vy', 'SD - Vz', 'r - Vx', 'r - Vy','r - Vz'])\n",
    "\n",
    "for clus_cube_size in [160000, 200000, 240000, 280000, 320000]:\n",
    "    for cell_size in [2000, 4000, 5000, 8000, 10000, 20000]:\n",
    "        \n",
    "        print(cell_size, clus_cube_size)\n",
    "                \n",
    "        no_of_cells = clus_cube_size//cell_size\n",
    "        \n",
    "        clus_cube_size_actual = clus_cube_size\n",
    "        \n",
    "        if no_of_cells % 2 != 0:\n",
    "            clus_cube_size = clus_cube_size + cell_size\n",
    "        \n",
    "        sigma_in_pix = sigma_calc(cell_size)\n",
    "\n",
    "        df_clusters = edge_clus_remover(clus_cube_size)\n",
    "\n",
    "        delta_gal_mean = delta_gal_mean_func(cell_size)\n",
    "\n",
    "        vel_terms = vel_terms_calc(cell_size, clus_cube_size)\n",
    "\n",
    "        clus_param = list(zip(df_clusters['x[kpc/h]'], df_clusters['y[kpc/h]'], df_clusters['z[kpc/h]'], \n",
    "                              [delta_gal_mean]*len(df_clusters), [cell_size]*len(df_clusters), \n",
    "                              [vel_terms]*len(df_clusters), [sigma_in_pix]*len(df_clusters),\n",
    "                              [clus_cube_size]*len(df_clusters)))\n",
    "\n",
    "        pool = multi.Pool(processes = cores)\n",
    "        v_est = pool.starmap(clus_velocity_calc, clus_param)\n",
    "\n",
    "        df_clusters_est_err = df_clusters.copy()\n",
    "\n",
    "        df_clusters_est_err['vx_est[km/s]'] = [i[0] for i in v_est]\n",
    "        df_clusters_est_err['vy_est[km/s]'] = [i[1] for i in v_est]\n",
    "        df_clusters_est_err['vz_est[km/s]'] = [i[2] for i in v_est]\n",
    "\n",
    "        df_clusters_est_err['vx_err[km/s]'] = df_clusters_est_err['vx[km/s]'] - df_clusters_est_err['vx_est[km/s]']\n",
    "        df_clusters_est_err['vy_err[km/s]'] = df_clusters_est_err['vy[km/s]'] - df_clusters_est_err['vy_est[km/s]']\n",
    "        df_clusters_est_err['vz_err[km/s]'] = df_clusters_est_err['vz[km/s]'] - df_clusters_est_err['vz_est[km/s]']\n",
    "        \n",
    "        plotting_func(df_clusters_est_err, cell_size, clus_cube_size_actual)\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "        cube_cell_size_assess = cube_cell_size_assess.append({'Cell Size': cell_size,\n",
    "                'Act Cube Size': clus_cube_size_actual,\n",
    "                'Cube Size Set': clus_cube_size,\n",
    "                'Clusters': len(df_clusters),\n",
    "                'Mean - Vx': round(np.mean(df_clusters_est_err['vx_err[km/s]']),1), \n",
    "                'Mean - Vy': round(np.mean(df_clusters_est_err['vy_err[km/s]']),1), \n",
    "                'Mean - Vz': round(np.mean(df_clusters_est_err['vz_err[km/s]']),1), \n",
    "                'SD - Vx': round(np.std(df_clusters_est_err['vx_err[km/s]']),1), \n",
    "                'SD - Vy': round(np.std(df_clusters_est_err['vy_err[km/s]']),1),\n",
    "                'SD - Vz': round(np.std(df_clusters_est_err['vz_err[km/s]']),1), \n",
    "                'r - Vx': round(np.corrcoef(df_clusters['vx[km/s]'], df_clusters_est_err['vx_est[km/s]'])[1,0],2),\n",
    "                'r - Vy': round(np.corrcoef(df_clusters['vy[km/s]'], df_clusters_est_err['vy_est[km/s]'])[1,0],2),\n",
    "                'r - Vz': round(np.corrcoef(df_clusters['vz[km/s]'], df_clusters_est_err['vz_est[km/s]'])[1,0],2)}, \n",
    "                ignore_index=True)\n",
    "        \n",
    "        clus_cube_size = clus_cube_size_actual\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing & seeing the assesment table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_cell_size_assess.to_excel('cube_cell_size_assess.xlsx')\n",
    "cube_cell_size_assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshaping the Pearson's r for Vz column into a more easy-to-read form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_Vz_table = pd.DataFrame()\n",
    "\n",
    "for name, group in cube_cell_size_assess.groupby(\"Cell Size\"):\n",
    "    if r_Vz_table.empty:\n",
    "        r_Vz_table = group.set_index(\"Act Cube Size\")[[\"r - Vz\"]].rename(columns={\"r - Vz\":name})\n",
    "    else:\n",
    "        r_Vz_table = r_Vz_table.join(group.set_index(\"Act Cube Size\")[[\"r - Vz\"]].rename(columns={\"r - Vz\":name}))\n",
    "\n",
    "r_Vz_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the mean, SD & r response due to variation of cell sizes for a given cluster cube size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(0,6)\n",
    "\n",
    "# for clus_cube_size in [240000]:\n",
    "for clus_cube_size in [160000, 200000, 240000, 280000, 320000]:\n",
    "\n",
    "    plt.figure(dpi = dpi, figsize = (5,9))\n",
    "    plt.subplot(311)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['Mean - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['Mean - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['Mean - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cell size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('Mean of error (km/s)')\n",
    "    plt.xticks(x_axis, [2000, 4000, 5000, 8000, 10000, 20000])\n",
    "    minus_one = {-1}\n",
    "    plt.title(r'Mean of velocity error | Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), fontsize = 11)\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['SD - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['SD - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['SD - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cell size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('SD of error (km/s)')\n",
    "    plt.xticks(x_axis, [2000, 4000, 5000, 8000, 10000, 20000])\n",
    "    minus_one = {-1}\n",
    "    plt.title(r'SD of velocity error | Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), fontsize = 11)\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['r - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['r - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Act Cube Size'] == clus_cube_size]['r - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cell size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('Pearson\\'s r')\n",
    "    plt.xticks(x_axis, [2000, 4000, 5000, 8000, 10000, 20000])\n",
    "    minus_one = {-1}\n",
    "    plt.title(r\"Pearson's r | Cube size: {} h$^{}$kpc\".format(clus_cube_size, minus_one), fontsize = 11)\n",
    "    plt.subplots_adjust(hspace = 0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Plots/cell_size_exam/clus_box_{clus_cube_size}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the mean, SD & r response due to variation of cluster cube sizes for a given cell size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_axis = np.arange(0,5)\n",
    "\n",
    "# for cell_size in [5000]:\n",
    "for cell_size in [2000, 4000, 5000, 8000, 10000, 20000]:\n",
    "\n",
    "    plt.figure(dpi = dpi, figsize = (5,10))\n",
    "    plt.subplot(311)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['Mean - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['Mean - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['Mean - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cube size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('Mean of error (km/s)')\n",
    "    plt.xticks(x_axis, [160000, 200000, 240000, 280000, 320000])\n",
    "    plt.ylim(-750,50)\n",
    "    minus_one = {-1}\n",
    "    plt.title(r'Mean of velocity error | Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), fontsize = 11)\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['SD - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['SD - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['SD - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cube size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('SD of error (km/s)')\n",
    "    plt.ylim(100, 950)\n",
    "    plt.xticks(x_axis, [160000, 200000, 240000, 280000, 320000])\n",
    "    plt.title(r'SD of velocity error | Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), fontsize = 11)\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['r - Vx'], label = 'Vx')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['r - Vy'], label = 'Vy')\n",
    "    plt.plot(x_axis, cube_cell_size_assess[cube_cell_size_assess['Cell Size'] == cell_size]['r - Vz'], label = 'Vz')\n",
    "    plt.legend()\n",
    "    plt.xlabel(r'Cube size (h$^{-1}$kpc)')\n",
    "    plt.ylabel('Pearson\\'s r')\n",
    "    plt.xticks(x_axis, [160000, 200000, 240000, 280000, 320000])\n",
    "    plt.ylim(0.30, 0.90)\n",
    "    plt.title(r\"Pearson's r | Cell size: {} h$^{}$kpc\".format(cell_size, minus_one), fontsize = 11)\n",
    "\n",
    "    plt.subplots_adjust(hspace = 0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Plots/clus_bos_size_exam/cell_size_{cell_size}.png')\n",
    "#     plt.savefig(f'Plots/clus_bos_size_exam/free_y_lim/cell_size_{cell_size}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtaining velocity estimates for a given cell size & cluster box size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cell_size = 10000                      #h^-1 kpc, size of pixel or cell\n",
    "\n",
    "clus_cube_size = 240000\n",
    "\n",
    "no_of_cells = clus_cube_size//cell_size\n",
    "if no_of_cells % 2 != 0:\n",
    "    clus_cube_size = clus_cube_size + cell_size\n",
    "    \n",
    "df_clusters = edge_clus_remover(clus_cube_size)\n",
    "\n",
    "sigma_in_pix = sigma_calc(cell_size)\n",
    "\n",
    "delta_gal_mean = delta_gal_mean_func(cell_size)\n",
    "\n",
    "vel_terms = vel_terms_calc(cell_size, clus_cube_size)\n",
    "\n",
    "clus_param = list(zip(df_clusters['x[kpc/h]'], df_clusters['y[kpc/h]'], df_clusters['z[kpc/h]'], \n",
    "                      [delta_gal_mean]*len(df_clusters), [cell_size]*len(df_clusters), \n",
    "                      [vel_terms]*len(df_clusters), [sigma_in_pix]*len(df_clusters),\n",
    "                      [clus_cube_size]*len(df_clusters)))\n",
    "\n",
    "pool = multi.Pool(processes = cores)\n",
    "v_est = pool.starmap(clus_velocity_calc, clus_param)\n",
    "\n",
    "df_clusters_est_err = df_clusters.copy()\n",
    "\n",
    "df_clusters_est_err['vx_est[km/s]'] = [i[0] for i in v_est]\n",
    "df_clusters_est_err['vy_est[km/s]'] = [i[1] for i in v_est]\n",
    "df_clusters_est_err['vz_est[km/s]'] = [i[2] for i in v_est]\n",
    "\n",
    "df_clusters_est_err['vx_err[km/s]'] = df_clusters_est_err['vx[km/s]'] - df_clusters_est_err['vx_est[km/s]']\n",
    "df_clusters_est_err['vy_err[km/s]'] = df_clusters_est_err['vy[km/s]'] - df_clusters_est_err['vy_est[km/s]']\n",
    "df_clusters_est_err['vz_err[km/s]'] = df_clusters_est_err['vz[km/s]'] - df_clusters_est_err['vz_est[km/s]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assessing the correctness of the estimated velocities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig = plt.figure(dpi = dpi, figsize = (10,12))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.scatter(df_clusters_est_err['vx[km/s]'], df_clusters_est_err['vx_est[km/s]'], s = 8)\n",
    "plt.xlabel('V$_\\mathrm{x, true}$ (km/s)')\n",
    "plt.ylabel('V$_\\mathrm{x, estimated}$ (km/s)')\n",
    "plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "plt.ylim(-2000,2000)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title('Vx - scatter plot')\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "error_x = df_clusters_est_err['vx[km/s]'] - df_clusters_est_err['vx_est[km/s]']\n",
    "plt.hist(error_x, bins = 100)\n",
    "plt.xlabel('Error in V$_{\\mathrm{x}}$ (km/s)')\n",
    "plt.ylabel('Number of clusters')\n",
    "x_low, x_high = plt.xlim()\n",
    "plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "minus_one = {-1}\n",
    "plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.76, f'Mean: {round(np.mean(error_x), 1)} km/s', transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.69, f'SD: {round(np.std(error_x), 1)} km/s', transform=plt.gca().transAxes)\n",
    "r_vx = np.corrcoef(df_clusters_est_err['vx[km/s]'], df_clusters_est_err['vx_est[km/s]'])[1,0]\n",
    "plt.text(0.57, 0.62, f'Pearson\\'s r: {round(r_vx, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.title('Vx error - histogram')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.scatter(df_clusters_est_err['vy[km/s]'], df_clusters_est_err['vy_est[km/s]'], s = 8)\n",
    "plt.xlabel('V$_\\mathrm{y, true}$ (km/s)')\n",
    "plt.ylabel('V$_\\mathrm{y, estimated}$ (km/s)')\n",
    "plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "plt.ylim(-2000,2000)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title('Vy - scatter plot')\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "error_y = df_clusters_est_err['vy[km/s]'] - df_clusters_est_err['vy_est[km/s]']\n",
    "plt.hist(error_y, bins = 100)\n",
    "plt.xlabel('Error in V$_{\\mathrm{y}}$ (km/s)')\n",
    "plt.ylabel('Number of clusters')\n",
    "x_low, x_high = plt.xlim()\n",
    "plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "minus_one = {-1}\n",
    "plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.76, f'Mean: {round(np.mean(error_y), 1)} km/s', transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.69, f'SD: {round(np.std(error_y), 1)} km/s', transform=plt.gca().transAxes)\n",
    "r_vy = np.corrcoef(df_clusters_est_err['vy[km/s]'], df_clusters_est_err['vy_est[km/s]'])[1,0]\n",
    "plt.text(0.57, 0.62, f'Pearson\\'s r: {round(r_vy, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.title('Vy error - histogram')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.scatter(df_clusters_est_err['vz[km/s]'], df_clusters_est_err['vz_est[km/s]'], s = 8)\n",
    "plt.xlabel('V$_\\mathrm{z, true}$ (km/s)')\n",
    "plt.ylabel('V$_\\mathrm{z, estimated}$ (km/s)');\n",
    "plt.gca().set_xticks(range(-2000, 2001, 1000))\n",
    "plt.gca().set_yticks(range(-2000, 2001, 1000))\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.title('Vz - scatter plot')\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "error_z = df_clusters_est_err['vz[km/s]'] - df_clusters_est_err['vz_est[km/s]']\n",
    "plt.hist(error_z, bins = 100)\n",
    "plt.xlabel('Error in V$_{\\mathrm{z}}$ (km/s)')\n",
    "plt.ylabel('Number of clusters')\n",
    "x_low, x_high = plt.xlim()\n",
    "plt.xlim(x_low, abs(x_low))\n",
    "\n",
    "minus_one = {-1}\n",
    "plt.text(0.57, 0.90, r'Cell size: {} h$^{}$kpc'.format(cell_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.83, r'Cube size: {} h$^{}$kpc'.format(clus_cube_size, minus_one), transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.76, f'Mean: {round(np.mean(error_z), 1)} km/s', transform=plt.gca().transAxes)\n",
    "plt.text(0.57, 0.69, f'SD: {round(np.std(error_z), 1)} km/s', transform=plt.gca().transAxes)\n",
    "r_vz = np.corrcoef(df_clusters_est_err['vz[km/s]'], df_clusters_est_err['vz_est[km/s]'])[1,0]\n",
    "plt.text(0.57, 0.62, f'Pearson\\'s r: {round(r_vz, 2)}', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.title('Vz error - histogram')\n",
    "\n",
    "# os.system(f'mkdir Plots/{clus_cube_size}')\n",
    "plt.subplots_adjust(top = 0.9, hspace = 0.4, wspace = 0.3)\n",
    "plt.tight_layout()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the minimum value of mean & Sd, and maximum value of r**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cube_cell_size_assess['Mean - Vx'].abs().min())\n",
    "print(cube_cell_size_assess['Mean - Vy'].abs().min())\n",
    "print(cube_cell_size_assess['Mean - Vz'].abs().min())\n",
    "print(cube_cell_size_assess['SD - Vx'].abs().min())\n",
    "print(cube_cell_size_assess['SD - Vy'].abs().min())\n",
    "print(cube_cell_size_assess['SD - Vz'].abs().min())\n",
    "print(cube_cell_size_assess['r - Vx'].max())\n",
    "print(cube_cell_size_assess['r - Vy'].max())\n",
    "print(cube_cell_size_assess['r - Vz'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "1. All three components of velocities behave similarly so anyone of them can be taken from now onwards as the line of sight velocity. Pearson's r is highest (0.85) for V$_\\mathrm{z}$ so maybe prefer V$_\\mathrm{z}$ .\n",
    "2. The code to estimate velocity seems to work fine since:  \n",
    "(a) mean error in V$_\\mathrm{x}$ goes to 0.3 km/s for cell size of 10,000 h$^\\mathrm{-1}$kpc & cluster box size of 160,000 h$^\\mathrm{-1}$kpc (SD is 185 km/s & r is \t0.78 for this case)   \n",
    "(b) standard deviation of error in V$_\\mathrm{z}$ goes to 146 km/s for cell size of 10,000 h$^\\mathrm{-1}$kpc & cluster box size of 320,000 h$^\\mathrm{-1}$kpc (Mean is -41.7 km/s & r is 0.85 for this case)  \n",
    "(c) Pearson's r goes to 0.85 for V$_\\mathrm{z}$ estimates coming from cell size of 10,000 h$^\\mathrm{-1}$kpc & cluster box size of 280,000 h$^\\mathrm{-1}$kpc (Mean is -43 km/s & SD is 152 km/s for this case)\n",
    "3. Cell size of 10,000 h$^\\mathrm{-1}$kpc should be chosen since it gives least mean, SD & maximum r.\n",
    "4. Cluster box size does not make much difference but higher values do give a litter better mean, SD and r. A value of 280,000 h$^\\mathrm{-1}$kpc may be choszen since it give r of 0.85."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
